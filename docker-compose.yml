version: "3.8"

services:

  

  # city_intro:
  #   build: ./crawl/city_intro
  #   hostname: city_intro
  #   networks:
  #     - crawl

  redis_queue:
    image: redis:6.2
    restart: unless-stopped
    ports:
        - "6379:6379"
    hostname: redis_queue
    networks:
      - crawl

  hotel_link:
    build: ./crawl/hotel/hotel_link
    hostname: hotel_link
    depends_on:
      - redis_queue
    networks:
      - crawl


  crawler2:
    build: ./crawl/hotel/hotel_data
    hostname: crawler2
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    depends_on:
      - redis_queue
    memswap_limit: 4G
    shm_size: '2gb'
    networks:
      - crawl

  crawler3:
    build: ./crawl/hotel/hotel_data
    hostname: crawler3
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    depends_on:
      - redis_queue
    memswap_limit: 4G
    shm_size: '2gb'
    networks:
      - crawl

  crawler4:
    build: ./crawl/hotel/hotel_data
    hostname: crawler1
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    depends_on:
      - redis_queue
    memswap_limit: 4G
    networks:
      - crawl


  # zookeeper:
  #   image: bitnami/zookeeper:3.8
  #   ports:
  #     - "2181:2181"
  #   hostname: zookeeper
  #   # volumes:
  #   #   - "zookeeper_data:/bitnami"
  #   environment:
  #     - ALLOW_ANONYMOUS_LOGIN=yes
  #   networks:
  #     - crawl

  # kafka:
  #   image: bitnami/kafka:3.4
  #   ports:
  #     - "9092:9092"
  #   hostname: kafka
  #   # volumes:
  #   #   - "kafka_data:/bitnami"
  #   environment:
  #     - ALLOW_PLAINTEXT_LISTENER=yes
  #     - KAFKA_ENABLE_KRAFT=no
  #     - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
  #     - KAFKA_CFG_LISTENERS=PLAINTEXT://kafka:9092
  #   depends_on:
  #     - zookeeper
  #   # volumes:
  #   #   - ./process/kafka/server.properties:/opt/bitnami/kafka/server.properties
  #   networks:
  #     - crawl

  # spark-master:
  #   build: ./process/spark
  #   hostname: sparkMaster
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_MASTER_URL=spark://sparkMaster:7077
  #   volumes:
  #     - ./process/spark/process_data.py:/home/process_data.py
  #     # - SPARK_RPC_AUTH_SECRET=<secret>  # Set a secret value
  #   ports:
  #     - "8080:8080"  # Spark master UI port
  #     - "7077:7077"  # Spark master and worker communication port
  #     - "4040:4040"
  #   networks:
  #     - crawl

  # spark-worker:
  #   build: ./process/spark
  #   hostname: sparkWorker
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://sparkMaster:7077
  #   depends_on:
  #     - spark-master
  #   networks:
  #     - crawl

  cassandra:
    image: bitnami/cassandra:4.1
    container_name: cassandra
    ports:
      - "9042:9042"  # Cassandra client port
    volumes:
      - ./process/cassandra/init.cql:/docker-entrypoint-initdb.d/init.cql
      - ./data:/bitnami/cassandra/data  # Persist data to local directory
    networks:
      - crawl


      
networks:
  crawl: